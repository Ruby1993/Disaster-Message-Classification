{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/apple/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/apple/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/apple/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to /Users/apple/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "from sqlalchemy import create_engine\n",
    "import sqlalchemy as db\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import nltk \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import re\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.pipeline import Pipeline, FeatureUnion \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer \n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "nltk.download(['punkt', 'wordnet', 'averaged_perceptron_tagger','stopwords']) \n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
    "from nltk.stem.porter import PorterStemmer \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('data/DisasterResponse.db')\n",
    "res = conn.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "for name in res:\n",
    "    print (name[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine1 = create_engine('sqlite:///'+'data/DisasterResponse.db')\n",
    "df1=pd.read_sql('select * from messages;', conn)\n",
    "X1 = df.message.values\n",
    "Y1 = df.iloc[:,4:-1].values\n",
    "category_name1=list(df.columns[4:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26028,)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26028, 34)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    genre  related  request  offer  aid_related  medical_help  \\\n",
       "0  direct  1        0        0      0            0              \n",
       "1  direct  1        0        0      1            0              \n",
       "2  direct  1        0        0      0            0              \n",
       "3  direct  1        1        0      1            0              \n",
       "4  direct  1        0        0      0            0              \n",
       "\n",
       "   medical_products  search_and_rescue  security  military      ...        \\\n",
       "0  0                 0                  0         0             ...         \n",
       "1  0                 0                  0         0             ...         \n",
       "2  0                 0                  0         0             ...         \n",
       "3  1                 0                  0         0             ...         \n",
       "4  0                 0                  0         0             ...         \n",
       "\n",
       "   aid_centers  other_infrastructure  weather_related  floods  storm  fire  \\\n",
       "0  0            0                     0                0       0      0      \n",
       "1  0            0                     1                0       1      0      \n",
       "2  0            0                     0                0       0      0      \n",
       "3  0            0                     0                0       0      0      \n",
       "4  0            0                     0                0       0      0      \n",
       "\n",
       "   earthquake  cold  other_weather  direct_report  \n",
       "0  0           0     0              0              \n",
       "1  0           0     0              0              \n",
       "2  0           0     0              0              \n",
       "3  0           0     0              0              \n",
       "4  0           0     0              0              \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=df1.drop(['id','message','original'],axis=1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>direct</td>\n",
       "      <td>7182</td>\n",
       "      <td>3696</td>\n",
       "      <td>46</td>\n",
       "      <td>4338</td>\n",
       "      <td>592</td>\n",
       "      <td>471</td>\n",
       "      <td>216</td>\n",
       "      <td>131</td>\n",
       "      <td>46</td>\n",
       "      <td>...</td>\n",
       "      <td>78</td>\n",
       "      <td>186</td>\n",
       "      <td>1521</td>\n",
       "      <td>304</td>\n",
       "      <td>315</td>\n",
       "      <td>41</td>\n",
       "      <td>796</td>\n",
       "      <td>63</td>\n",
       "      <td>207</td>\n",
       "      <td>3613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news</td>\n",
       "      <td>10671</td>\n",
       "      <td>604</td>\n",
       "      <td>65</td>\n",
       "      <td>5860</td>\n",
       "      <td>1415</td>\n",
       "      <td>793</td>\n",
       "      <td>441</td>\n",
       "      <td>292</td>\n",
       "      <td>801</td>\n",
       "      <td>...</td>\n",
       "      <td>218</td>\n",
       "      <td>866</td>\n",
       "      <td>4280</td>\n",
       "      <td>1747</td>\n",
       "      <td>1445</td>\n",
       "      <td>225</td>\n",
       "      <td>910</td>\n",
       "      <td>415</td>\n",
       "      <td>1052</td>\n",
       "      <td>852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>social</td>\n",
       "      <td>2053</td>\n",
       "      <td>174</td>\n",
       "      <td>7</td>\n",
       "      <td>662</td>\n",
       "      <td>77</td>\n",
       "      <td>49</td>\n",
       "      <td>67</td>\n",
       "      <td>48</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>99</td>\n",
       "      <td>1496</td>\n",
       "      <td>104</td>\n",
       "      <td>683</td>\n",
       "      <td>16</td>\n",
       "      <td>749</td>\n",
       "      <td>52</td>\n",
       "      <td>117</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    genre  related  request  offer  aid_related  medical_help  \\\n",
       "0  direct  7182     3696     46     4338         592            \n",
       "1  news    10671    604      65     5860         1415           \n",
       "2  social  2053     174      7      662          77             \n",
       "\n",
       "   medical_products  search_and_rescue  security  military      ...        \\\n",
       "0  471               216                131       46            ...         \n",
       "1  793               441                292       801           ...         \n",
       "2  49                67                 48        13            ...         \n",
       "\n",
       "   aid_centers  other_infrastructure  weather_related  floods  storm  fire  \\\n",
       "0  78           186                   1521             304     315    41     \n",
       "1  218          866                   4280             1747    1445   225    \n",
       "2  13           99                    1496             104     683    16     \n",
       "\n",
       "   earthquake  cold  other_weather  direct_report  \n",
       "0  796         63    207            3613           \n",
       "1  910         415   1052           852            \n",
       "2  749         52    117            610            \n",
       "\n",
       "[3 rows x 36 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=df1.groupby('genre').sum().reset_index()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>types</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>direct</td>\n",
       "      <td>related</td>\n",
       "      <td>7182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news</td>\n",
       "      <td>related</td>\n",
       "      <td>10671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>social</td>\n",
       "      <td>related</td>\n",
       "      <td>2053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>direct</td>\n",
       "      <td>request</td>\n",
       "      <td>3696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>news</td>\n",
       "      <td>request</td>\n",
       "      <td>604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    genre    types  count\n",
       "0  direct  related  7182 \n",
       "1  news    related  10671\n",
       "2  social  related  2053 \n",
       "3  direct  request  3696 \n",
       "4  news    request  604  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=df2.melt(id_vars=['genre'], var_name='types', value_name='count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "      <th>types</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>direct</td>\n",
       "      <td>related</td>\n",
       "      <td>7182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news</td>\n",
       "      <td>related</td>\n",
       "      <td>10671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>social</td>\n",
       "      <td>related</td>\n",
       "      <td>2053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>direct</td>\n",
       "      <td>request</td>\n",
       "      <td>3696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>news</td>\n",
       "      <td>request</td>\n",
       "      <td>604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>social</td>\n",
       "      <td>request</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>direct</td>\n",
       "      <td>offer</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>news</td>\n",
       "      <td>offer</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>social</td>\n",
       "      <td>offer</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>direct</td>\n",
       "      <td>aid_related</td>\n",
       "      <td>4338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>news</td>\n",
       "      <td>aid_related</td>\n",
       "      <td>5860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>social</td>\n",
       "      <td>aid_related</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>direct</td>\n",
       "      <td>medical_help</td>\n",
       "      <td>592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>news</td>\n",
       "      <td>medical_help</td>\n",
       "      <td>1415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>social</td>\n",
       "      <td>medical_help</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>direct</td>\n",
       "      <td>medical_products</td>\n",
       "      <td>471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>news</td>\n",
       "      <td>medical_products</td>\n",
       "      <td>793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>social</td>\n",
       "      <td>medical_products</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>direct</td>\n",
       "      <td>search_and_rescue</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>news</td>\n",
       "      <td>search_and_rescue</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>social</td>\n",
       "      <td>search_and_rescue</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>direct</td>\n",
       "      <td>security</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>news</td>\n",
       "      <td>security</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>social</td>\n",
       "      <td>security</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>direct</td>\n",
       "      <td>military</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>news</td>\n",
       "      <td>military</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>social</td>\n",
       "      <td>military</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>direct</td>\n",
       "      <td>water</td>\n",
       "      <td>836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>news</td>\n",
       "      <td>water</td>\n",
       "      <td>790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>social</td>\n",
       "      <td>water</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>direct</td>\n",
       "      <td>aid_centers</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>news</td>\n",
       "      <td>aid_centers</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>social</td>\n",
       "      <td>aid_centers</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>direct</td>\n",
       "      <td>other_infrastructure</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>news</td>\n",
       "      <td>other_infrastructure</td>\n",
       "      <td>866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>social</td>\n",
       "      <td>other_infrastructure</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>direct</td>\n",
       "      <td>weather_related</td>\n",
       "      <td>1521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>news</td>\n",
       "      <td>weather_related</td>\n",
       "      <td>4280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>social</td>\n",
       "      <td>weather_related</td>\n",
       "      <td>1496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>direct</td>\n",
       "      <td>floods</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>news</td>\n",
       "      <td>floods</td>\n",
       "      <td>1747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>social</td>\n",
       "      <td>floods</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>direct</td>\n",
       "      <td>storm</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>news</td>\n",
       "      <td>storm</td>\n",
       "      <td>1445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>social</td>\n",
       "      <td>storm</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>direct</td>\n",
       "      <td>fire</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>news</td>\n",
       "      <td>fire</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>social</td>\n",
       "      <td>fire</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>direct</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>news</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>social</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>direct</td>\n",
       "      <td>cold</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>news</td>\n",
       "      <td>cold</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>social</td>\n",
       "      <td>cold</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>direct</td>\n",
       "      <td>other_weather</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>news</td>\n",
       "      <td>other_weather</td>\n",
       "      <td>1052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>social</td>\n",
       "      <td>other_weather</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>direct</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>3613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>news</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>social</td>\n",
       "      <td>direct_report</td>\n",
       "      <td>610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      genre                 types  count\n",
       "0    direct  related               7182 \n",
       "1    news    related               10671\n",
       "2    social  related               2053 \n",
       "3    direct  request               3696 \n",
       "4    news    request               604  \n",
       "5    social  request               174  \n",
       "6    direct  offer                 46   \n",
       "7    news    offer                 65   \n",
       "8    social  offer                 7    \n",
       "9    direct  aid_related           4338 \n",
       "10   news    aid_related           5860 \n",
       "11   social  aid_related           662  \n",
       "12   direct  medical_help          592  \n",
       "13   news    medical_help          1415 \n",
       "14   social  medical_help          77   \n",
       "15   direct  medical_products      471  \n",
       "16   news    medical_products      793  \n",
       "17   social  medical_products      49   \n",
       "18   direct  search_and_rescue     216  \n",
       "19   news    search_and_rescue     441  \n",
       "20   social  search_and_rescue     67   \n",
       "21   direct  security              131  \n",
       "22   news    security              292  \n",
       "23   social  security              48   \n",
       "24   direct  military              46   \n",
       "25   news    military              801  \n",
       "26   social  military              13   \n",
       "27   direct  water                 836  \n",
       "28   news    water                 790  \n",
       "29   social  water                 46   \n",
       "..      ...    ...                 ..   \n",
       "75   direct  aid_centers           78   \n",
       "76   news    aid_centers           218  \n",
       "77   social  aid_centers           13   \n",
       "78   direct  other_infrastructure  186  \n",
       "79   news    other_infrastructure  866  \n",
       "80   social  other_infrastructure  99   \n",
       "81   direct  weather_related       1521 \n",
       "82   news    weather_related       4280 \n",
       "83   social  weather_related       1496 \n",
       "84   direct  floods                304  \n",
       "85   news    floods                1747 \n",
       "86   social  floods                104  \n",
       "87   direct  storm                 315  \n",
       "88   news    storm                 1445 \n",
       "89   social  storm                 683  \n",
       "90   direct  fire                  41   \n",
       "91   news    fire                  225  \n",
       "92   social  fire                  16   \n",
       "93   direct  earthquake            796  \n",
       "94   news    earthquake            910  \n",
       "95   social  earthquake            749  \n",
       "96   direct  cold                  63   \n",
       "97   news    cold                  415  \n",
       "98   social  cold                  52   \n",
       "99   direct  other_weather         207  \n",
       "100  news    other_weather         1052 \n",
       "101  social  other_weather         117  \n",
       "102  direct  direct_report         3613 \n",
       "103  news    direct_report         852  \n",
       "104  social  direct_report         610  \n",
       "\n",
       "[105 rows x 3 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "test=df1.sum()\n",
    "test=pd.DataFrame(test,index=None)\n",
    "print (type(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 0], dtype='object')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     related               \n",
       "1     request               \n",
       "2     offer                 \n",
       "3     aid_related           \n",
       "4     medical_help          \n",
       "5     medical_products      \n",
       "6     search_and_rescue     \n",
       "7     security              \n",
       "8     military              \n",
       "9     water                 \n",
       "10    food                  \n",
       "11    shelter               \n",
       "12    clothing              \n",
       "13    money                 \n",
       "14    missing_people        \n",
       "15    refugees              \n",
       "16    death                 \n",
       "17    other_aid             \n",
       "18    infrastructure_related\n",
       "19    transport             \n",
       "20    buildings             \n",
       "21    electricity           \n",
       "22    tools                 \n",
       "23    hospitals             \n",
       "24    shops                 \n",
       "25    aid_centers           \n",
       "26    other_infrastructure  \n",
       "27    weather_related       \n",
       "28    floods                \n",
       "29    storm                 \n",
       "30    fire                  \n",
       "31    earthquake            \n",
       "32    cold                  \n",
       "33    other_weather         \n",
       "34    direct_report         \n",
       "Name: index, dtype: object"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///'+'DisasterResponse.db')\n",
    "df=pd.read_sql(\"messages\", engine)\n",
    "X = df.message.values\n",
    "Y = df.iloc[:,4:-1].values\n",
    "category_name=list(df.columns[4:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26028, 39)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text=re.sub(r\"[^a-zA-Z0-9]\",\" \",text)\n",
    "    words=word_tokenize(text)\n",
    "    words=[w.lower().strip() for w in words if w not in stopwords.words('english')]\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed = [PorterStemmer().stem(w) for w in words] \n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer = tokenize)), \n",
    "    ('tfidf', TfidfTransformer()), \n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>water</th>\n",
       "      <th>...</th>\n",
       "      <th>shops</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6122</td>\n",
       "      <td>21554</td>\n",
       "      <td>25910</td>\n",
       "      <td>15168</td>\n",
       "      <td>23944</td>\n",
       "      <td>24715</td>\n",
       "      <td>25304</td>\n",
       "      <td>25557</td>\n",
       "      <td>25168</td>\n",
       "      <td>24356</td>\n",
       "      <td>...</td>\n",
       "      <td>25908</td>\n",
       "      <td>25719</td>\n",
       "      <td>24877</td>\n",
       "      <td>18731</td>\n",
       "      <td>23873</td>\n",
       "      <td>23585</td>\n",
       "      <td>25746</td>\n",
       "      <td>23573</td>\n",
       "      <td>25498</td>\n",
       "      <td>24652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19906</td>\n",
       "      <td>4474</td>\n",
       "      <td>118</td>\n",
       "      <td>10860</td>\n",
       "      <td>2084</td>\n",
       "      <td>1313</td>\n",
       "      <td>724</td>\n",
       "      <td>471</td>\n",
       "      <td>860</td>\n",
       "      <td>1672</td>\n",
       "      <td>...</td>\n",
       "      <td>120</td>\n",
       "      <td>309</td>\n",
       "      <td>1151</td>\n",
       "      <td>7297</td>\n",
       "      <td>2155</td>\n",
       "      <td>2443</td>\n",
       "      <td>282</td>\n",
       "      <td>2455</td>\n",
       "      <td>530</td>\n",
       "      <td>1376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   related  request  offer  aid_related  medical_help  medical_products  \\\n",
       "0  6122     21554    25910  15168        23944         24715              \n",
       "1  19906    4474     118    10860        2084          1313               \n",
       "\n",
       "   search_and_rescue  security  military  water      ...        shops  \\\n",
       "0  25304              25557     25168     24356      ...        25908   \n",
       "1  724                471       860       1672       ...        120     \n",
       "\n",
       "   aid_centers  other_infrastructure  weather_related  floods  storm   fire  \\\n",
       "0  25719        24877                 18731            23873   23585  25746   \n",
       "1  309          1151                  7297             2155    2443   282     \n",
       "\n",
       "   earthquake   cold  other_weather  \n",
       "0  23573       25498  24652          \n",
       "1  2455        530    1376           \n",
       "\n",
       "[2 rows x 34 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Understand the values in 0 and 1\n",
    "df.iloc[:,4:-1].apply(pd.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function tokenize at...\n",
       "                                                                        ccp_alpha=0.0,\n",
       "                                                                        class_weight=None,\n",
       "                                                                        criterion='gini',\n",
       "                                                                        max_depth=None,\n",
       "                                                                        max_features='auto',\n",
       "                                                                        max_leaf_nodes=None,\n",
       "                                                                        max_samples=None,\n",
       "                                                                        min_impurity_decrease=0.0,\n",
       "                                                                        min_impurity_split=None,\n",
       "                                                                        min_samples_leaf=1,\n",
       "                                                                        min_samples_split=2,\n",
       "                                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                                        n_estimators=100,\n",
       "                                                                        n_jobs=None,\n",
       "                                                                        oob_score=False,\n",
       "                                                                        random_state=None,\n",
       "                                                                        verbose=0,\n",
       "                                                                        warm_start=False),\n",
       "                                       n_jobs=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "pipeline.fit(X_train,y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_predicted = pipeline.predict(X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Precision    Recall  Accuracy        f1\n",
      "related                 0.998990   0.997541  0.997359  0.998265\n",
      "request                 0.998815   0.995277  0.998799  0.997043\n",
      "offer                   1.000000   0.988636  0.999952  0.994286\n",
      "aid_related             0.998455   0.997743  0.998463  0.998099\n",
      "medical_help            1.000000   0.992000  0.999424  0.995984\n",
      "medical_products        0.998948   0.994764  0.999712  0.996852\n",
      "search_and_rescue       1.000000   0.990809  0.999760  0.995383\n",
      "security                1.000000   0.976048  0.999616  0.987879\n",
      "military                1.000000   0.992754  0.999856  0.996364\n",
      "water                   1.000000   0.999249  0.999952  0.999624\n",
      "food                    1.000000   0.998779  0.999856  0.999389\n",
      "shelter                 1.000000   0.998353  0.999856  0.999176\n",
      "clothing                1.000000   0.997041  0.999952  0.998519\n",
      "money                   1.000000   0.993840  0.999856  0.996910\n",
      "missing_people          1.000000   0.995885  0.999952  0.997938\n",
      "refugees                1.000000   0.994915  0.999856  0.997451\n",
      "death                   0.998908   0.997819  0.999856  0.998363\n",
      "other_aid               0.997525   0.992262  0.998607  0.994886\n",
      "infrastructure_related  0.999197   0.993615  0.999568  0.996399\n",
      "transport               0.998815   0.988277  0.999472  0.993518\n",
      "buildings               1.000000   0.997110  0.999856  0.998553\n",
      "electricity             1.000000   1.000000  1.000000  1.000000\n",
      "tools                   1.000000   0.982456  0.999904  0.991150\n",
      "hospitals               1.000000   1.000000  1.000000  1.000000\n",
      "shops                   1.000000   0.989362  0.999952  0.994652\n",
      "aid_centers             1.000000   0.995169  0.999952  0.997579\n",
      "other_infrastructure    0.998832   0.996503  0.999808  0.997666\n",
      "weather_related         0.998398   0.998718  0.999136  0.998558\n",
      "floods                  0.999397   0.996392  0.999664  0.997892\n",
      "storm                   0.999545   0.997278  0.999664  0.998410\n",
      "fire                    1.000000   0.995614  0.999952  0.997802\n",
      "earthquake              0.996914   0.998675  0.999520  0.997793\n",
      "cold                    0.997840   0.993548  0.999808  0.995690\n",
      "other_weather           0.998175   0.994545  0.999616  0.996357\n"
     ]
    }
   ],
   "source": [
    "metrics=[]\n",
    "for i in range(len(category_name)):\n",
    "    precision=precision_score(y_train[:,i],y_train_predicted[:,i])\n",
    "    recall=recall_score(y_train[:,i],y_train_predicted[:,i])\n",
    "    accuracy=accuracy_score(y_train[:,i],y_train_predicted[:,i])\n",
    "    f1=f1_score(list(y_train[:,i]),list(y_train_predicted[:,i]))\n",
    "    \n",
    "    metrics.append([precision,recall,accuracy,f1])\n",
    "    \n",
    "# Metrics output\n",
    "metrics_output=pd.DataFrame(data=metrics,columns=['Precision','Recall','Accuracy','f1'],index = category_name)\n",
    "print (metrics_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Precision    1.000000\n",
       "Recall       0.995446\n",
       "Accuracy     0.999832\n",
       "f1           0.997622\n",
       "dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_output.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Precision    0.999375\n",
       "Recall       0.994441\n",
       "Accuracy     0.999604\n",
       "f1           0.996895\n",
       "dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_output.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test the model on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_predicted = pipeline.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/anaconda/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Precision    Recall  Accuracy        f1\n",
      "related                 0.805261   0.976026  0.797925  0.882458\n",
      "request                 0.370370   0.041841  0.952747  0.075188\n",
      "offer                   0.000000   0.000000  0.994237  0.000000\n",
      "aid_related             0.710069   0.670217  0.717057  0.689568\n",
      "medical_help            0.700000   0.083904  0.893200  0.149847\n",
      "medical_products        0.800000   0.033520  0.932962  0.064343\n",
      "search_and_rescue       0.722222   0.072222  0.966961  0.131313\n",
      "security                0.000000   0.000000  0.973300  0.000000\n",
      "military                0.700000   0.031390  0.915866  0.060086\n",
      "water                   0.731343   0.144118  0.940645  0.240786\n",
      "food                    0.684211   0.335484  0.926815  0.450216\n",
      "shelter                 0.785714   0.290650  0.925471  0.424332\n",
      "clothing                1.000000   0.014925  0.987322  0.029412\n",
      "money                   0.000000   0.000000  0.977526  0.000000\n",
      "missing_people          0.000000   0.000000  0.989435  0.000000\n",
      "refugees                0.875000   0.073684  0.948713  0.135922\n",
      "death                   0.629630   0.061372  0.948137  0.111842\n",
      "other_aid               0.000000   0.000000  0.883788  0.000000\n",
      "infrastructure_related  0.250000   0.002212  0.912793  0.004386\n",
      "transport               0.896552   0.074713  0.937572  0.137931\n",
      "buildings               0.818182   0.061017  0.946024  0.113565\n",
      "electricity             0.933333   0.101449  0.975989  0.183007\n",
      "tools                   0.000000   0.000000  0.991356  0.000000\n",
      "hospitals               0.000000   0.000000  0.982904  0.000000\n",
      "shops                   0.000000   0.000000  0.995006  0.000000\n",
      "aid_centers             0.000000   0.000000  0.980407  0.000000\n",
      "other_infrastructure    0.000000   0.000000  0.943335  0.000000\n",
      "weather_related         0.848322   0.599052  0.897042  0.702222\n",
      "floods                  0.905660   0.487805  0.946792  0.634082\n",
      "storm                   0.773109   0.384937  0.966577  0.513966\n",
      "fire                    0.000000   0.000000  0.989627  0.000000\n",
      "earthquake              0.873016   0.575916  0.981368  0.694006\n",
      "cold                    1.000000   0.015385  0.987706  0.030303\n",
      "other_weather           0.200000   0.003623  0.946408  0.007117\n"
     ]
    }
   ],
   "source": [
    "metrics_test=[]\n",
    "for i in range(len(category_name)):\n",
    "    precision=precision_score(y_test[:,i],y_test_predicted[:,i])\n",
    "    recall=recall_score(y_test[:,i],y_test_predicted[:,i])\n",
    "    accuracy=accuracy_score(y_test[:,i],y_test_predicted[:,i])\n",
    "    f1=f1_score(list(y_test[:,i]),list(y_test_predicted[:,i]))\n",
    "    \n",
    "    metrics_test.append([precision,recall,accuracy,f1])\n",
    "    \n",
    "# Metrics output\n",
    "metrics_output_test=pd.DataFrame(data=metrics_test,columns=['Precision','Recall','Accuracy','f1'],index = category_name)\n",
    "print (metrics_output_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Precision    0.700000\n",
       "Recall       0.037680\n",
       "Accuracy     0.948425\n",
       "f1           0.069766\n",
       "dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_output_test.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Precision    0.500353\n",
       "Recall       0.151043\n",
       "Accuracy     0.942736\n",
       "f1           0.190174\n",
       "dtype: float64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_output_test.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf': MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                        ccp_alpha=0.0,\n",
       "                                                        class_weight=None,\n",
       "                                                        criterion='gini',\n",
       "                                                        max_depth=None,\n",
       "                                                        max_features='auto',\n",
       "                                                        max_leaf_nodes=None,\n",
       "                                                        max_samples=None,\n",
       "                                                        min_impurity_decrease=0.0,\n",
       "                                                        min_impurity_split=None,\n",
       "                                                        min_samples_leaf=1,\n",
       "                                                        min_samples_split=2,\n",
       "                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                        n_estimators=100,\n",
       "                                                        n_jobs=None,\n",
       "                                                        oob_score=False,\n",
       "                                                        random_state=None,\n",
       "                                                        verbose=0,\n",
       "                                                        warm_start=False),\n",
       "                       n_jobs=None),\n",
       " 'clf__estimator': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                        criterion='gini', max_depth=None, max_features='auto',\n",
       "                        max_leaf_nodes=None, max_samples=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                        n_jobs=None, oob_score=False, random_state=None,\n",
       "                        verbose=0, warm_start=False),\n",
       " 'clf__estimator__bootstrap': True,\n",
       " 'clf__estimator__ccp_alpha': 0.0,\n",
       " 'clf__estimator__class_weight': None,\n",
       " 'clf__estimator__criterion': 'gini',\n",
       " 'clf__estimator__max_depth': None,\n",
       " 'clf__estimator__max_features': 'auto',\n",
       " 'clf__estimator__max_leaf_nodes': None,\n",
       " 'clf__estimator__max_samples': None,\n",
       " 'clf__estimator__min_impurity_decrease': 0.0,\n",
       " 'clf__estimator__min_impurity_split': None,\n",
       " 'clf__estimator__min_samples_leaf': 1,\n",
       " 'clf__estimator__min_samples_split': 2,\n",
       " 'clf__estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'clf__estimator__n_estimators': 100,\n",
       " 'clf__estimator__n_jobs': None,\n",
       " 'clf__estimator__oob_score': False,\n",
       " 'clf__estimator__random_state': None,\n",
       " 'clf__estimator__verbose': 0,\n",
       " 'clf__estimator__warm_start': False,\n",
       " 'clf__n_jobs': None,\n",
       " 'memory': None,\n",
       " 'steps': [('vect',\n",
       "   CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                   dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                   lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                   ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                   strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                   tokenizer=<function tokenize at 0x7fd686ecbc80>,\n",
       "                   vocabulary=None)),\n",
       "  ('tfidf',\n",
       "   TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)),\n",
       "  ('clf',\n",
       "   MultiOutputClassifier(estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                          ccp_alpha=0.0,\n",
       "                                                          class_weight=None,\n",
       "                                                          criterion='gini',\n",
       "                                                          max_depth=None,\n",
       "                                                          max_features='auto',\n",
       "                                                          max_leaf_nodes=None,\n",
       "                                                          max_samples=None,\n",
       "                                                          min_impurity_decrease=0.0,\n",
       "                                                          min_impurity_split=None,\n",
       "                                                          min_samples_leaf=1,\n",
       "                                                          min_samples_split=2,\n",
       "                                                          min_weight_fraction_leaf=0.0,\n",
       "                                                          n_estimators=100,\n",
       "                                                          n_jobs=None,\n",
       "                                                          oob_score=False,\n",
       "                                                          random_state=None,\n",
       "                                                          verbose=0,\n",
       "                                                          warm_start=False),\n",
       "                         n_jobs=None))],\n",
       " 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True),\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__use_idf': True,\n",
       " 'vect': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                 dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                 lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                 ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                 strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                 tokenizer=<function tokenize at 0x7fd686ecbc80>,\n",
       "                 vocabulary=None),\n",
       " 'vect__analyzer': 'word',\n",
       " 'vect__binary': False,\n",
       " 'vect__decode_error': 'strict',\n",
       " 'vect__dtype': numpy.int64,\n",
       " 'vect__encoding': 'utf-8',\n",
       " 'vect__input': 'content',\n",
       " 'vect__lowercase': True,\n",
       " 'vect__max_df': 1.0,\n",
       " 'vect__max_features': None,\n",
       " 'vect__min_df': 1,\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__preprocessor': None,\n",
       " 'vect__stop_words': None,\n",
       " 'vect__strip_accents': None,\n",
       " 'vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vect__tokenizer': <function __main__.tokenize>,\n",
       " 'vect__vocabulary': None,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'tfidf__norm': ('l1', 'l2'),\n",
    "        'clf__estimator__n_estimators': [10,50,100],\n",
    "        'clf__estimator__min_samples_split': [2, 3, 4]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def performance_metric(y_test,y_pred):\n",
    "\n",
    "    score_list=[]\n",
    "    for i in range(np.shape(y_test)[1]):\n",
    "        f1=f1_score(y_true=list(y_test[:,i]),y_pred=list(y_pred[:,i]))\n",
    "        score_list.append(f1)\n",
    "    score=np.median(score_list)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1_scorer = make_scorer(performance_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = GridSearchCV(pipeline, param_grid=parameters,scoring=f1_scorer,verbose=10)\n",
    "#cv = GridSearchCV(pipeline, param_grid = parameters, scoring = scorer, verbose = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=True, score=0.083, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=True, score=0.103, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  4.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=True, score=0.103, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  7.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=True, score=0.134, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=True \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  9.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=True, score=0.090, total= 2.4min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 11.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=False, score=0.080, total= 2.4min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 14.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=False, score=0.125, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed: 16.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=False, score=0.134, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 18.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=False, score=0.092, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 20.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=False, score=0.111, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=True, score=0.114, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=True, score=0.132, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=True, score=0.139, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=True, score=0.133, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=True, score=0.110, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=False, score=0.098, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=False, score=0.121, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=False, score=0.144, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=False, score=0.116, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=False, score=0.105, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=True, score=0.059, total= 4.1min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=True, score=0.100, total= 4.1min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=True, score=0.094, total= 4.1min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=True, score=0.095, total= 4.2min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=True, score=0.105, total= 4.1min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=False, score=0.066, total= 4.2min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=False, score=0.077, total= 4.2min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=False, score=0.128, total= 4.2min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=False, score=0.106, total= 4.2min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=False, score=0.082, total= 4.3min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=True, score=0.104, total= 4.1min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=True, score=0.106, total= 4.2min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=True, score=0.112, total= 4.2min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=True, score=0.116, total= 4.2min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=True, score=0.107, total= 4.2min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=False, score=0.093, total= 4.2min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=False, score=0.130, total= 4.2min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=False, score=0.111, total= 4.2min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=False, score=0.087, total= 4.2min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=False, score=0.065, total= 4.2min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=True, score=0.072, total= 6.4min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=True, score=0.091, total= 6.5min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=True \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=True, score=0.081, total= 6.5min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=True, score=0.091, total= 6.5min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=True, score=0.067, total= 6.5min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=False, score=0.071, total= 6.5min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=False, score=0.108, total= 6.6min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=False, score=0.098, total= 6.5min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=False, score=0.094, total= 6.5min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=False, score=0.068, total= 6.6min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=True, score=0.071, total= 6.4min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=True, score=0.116, total= 6.5min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=True, score=0.088, total= 6.5min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=True, score=0.117, total= 6.5min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=True, score=0.090, total= 6.5min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=False, score=0.071, total= 6.5min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=False, score=0.114, total= 6.6min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=False, score=0.104, total= 6.6min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=False, score=0.084, total= 6.6min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=False, score=0.084, total= 6.6min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=True, score=0.118, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=True, score=0.147, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=True, score=0.171, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=True, score=0.148, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=True, score=0.112, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=False, score=0.140, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=False, score=0.131, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=False, score=0.134, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=False, score=0.159, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=False, score=0.133, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=True, score=0.159, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=True, score=0.147, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=True, score=0.182, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=True, score=0.152, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=True, score=0.209, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=False \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=False, score=0.121, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=False, score=0.162, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=False, score=0.177, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=False, score=0.112, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=False, score=0.145, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=True, score=0.101, total= 3.9min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=True, score=0.106, total= 3.9min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=True, score=0.113, total= 3.9min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=True, score=0.102, total= 3.9min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=True, score=0.062, total= 3.9min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=False, score=0.077, total= 3.9min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=False, score=0.078, total= 3.9min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=False, score=0.113, total= 3.9min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=False, score=0.106, total= 3.9min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=False, score=0.095, total= 3.9min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=True, score=0.084, total= 3.9min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=True, score=0.140, total= 3.9min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=True, score=0.101, total= 3.9min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=True, score=0.117, total= 3.9min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=True, score=0.102, total= 4.0min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=False, score=0.111, total= 3.9min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=False, score=0.112, total= 3.9min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=False, score=0.102, total= 3.9min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=False, score=0.116, total= 3.9min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=False, score=0.108, total= 3.9min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=True, score=0.085, total= 5.9min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=True, score=0.107, total= 6.0min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=True, score=0.099, total= 6.0min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=True, score=0.087, total= 6.0min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=True, score=0.066, total= 6.0min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=False, score=0.079, total= 5.9min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=False, score=0.102, total= 5.9min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=False, score=0.107, total= 5.9min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=False \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=False, score=0.087, total= 5.9min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=False, score=0.091, total= 6.0min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=True, score=0.092, total= 5.9min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=True, score=0.112, total= 6.0min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=True, score=0.103, total= 6.0min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=True, score=0.080, total= 6.0min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=True, score=0.097, total= 6.0min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=False, score=0.108, total= 5.9min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=False, score=0.114, total= 6.0min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=False, score=0.095, total= 6.0min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=False, score=0.105, total= 6.0min\n",
      "[CV] clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=3, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=False, score=0.077, total= 6.0min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=True, score=0.137, total= 2.2min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=True, score=0.144, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=True, score=0.136, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=True, score=0.134, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=True, score=0.103, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=False, score=0.107, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=False, score=0.172, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=False, score=0.121, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=False, score=0.144, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l1, tfidf__use_idf=False, score=0.135, total= 2.2min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=True, score=0.189, total= 5.4min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=True, score=0.157, total= 2.8min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=True, score=0.197, total= 3.2min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=True, score=0.140, total= 2.2min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=True, score=0.163, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=False, score=0.180, total= 2.3min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=False, score=0.152, total= 3.0min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=False, score=0.147, total= 2.6min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=False, score=0.176, total= 2.4min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=10, tfidf__norm=l2, tfidf__use_idf=False, score=0.151, total= 2.4min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=True, score=0.079, total= 3.8min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=True \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=True, score=0.101, total= 4.0min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=True, score=0.110, total= 3.9min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=True, score=0.105, total= 3.8min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=True, score=0.086, total= 3.9min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=False, score=0.077, total= 3.8min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=False, score=0.109, total= 3.8min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=False, score=0.107, total= 4.0min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=False, score=0.109, total= 4.5min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l1, tfidf__use_idf=False, score=0.088, total= 4.3min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=True, score=0.094, total= 4.2min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=True, score=0.119, total= 4.2min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=True, score=0.114, total= 3.9min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=True, score=0.109, total= 3.9min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=True, score=0.084, total= 3.9min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=False, score=0.090, total= 3.9min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=False, score=0.123, total= 3.9min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=False, score=0.125, total= 3.9min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=False, score=0.110, total= 3.9min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=50, tfidf__norm=l2, tfidf__use_idf=False, score=0.089, total= 3.9min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=True, score=0.067, total= 6.7min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=True, score=0.122, total= 5.9min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=True, score=0.130, total= 5.8min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=True, score=0.095, total= 5.8min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=True, score=0.086, total= 5.9min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=False, score=0.069, total= 5.7min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=False, score=0.095, total= 5.8min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=False, score=0.077, total= 5.8min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=False, score=0.095, total= 5.8min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l1, tfidf__use_idf=False, score=0.067, total= 5.8min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=True, score=0.091, total= 5.9min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=True, score=0.095, total= 5.8min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=True, score=0.104, total= 5.9min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=True \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=True, score=0.078, total= 5.9min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=True \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=True, score=0.064, total= 5.9min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=False, score=0.092, total= 5.8min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=False, score=0.106, total= 5.8min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=False, score=0.098, total= 6.3min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=False, score=0.120, total= 6.2min\n",
      "[CV] clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=False \n",
      "[CV]  clf__estimator__min_samples_split=4, clf__estimator__n_estimators=100, tfidf__norm=l2, tfidf__use_idf=False, score=0.091, total= 6.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 180 out of 180 | elapsed: 752.7min finished\n"
     ]
    }
   ],
   "source": [
    "result=cv.fit(X_train, y_train)\n",
    "#model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([114.48539462, 115.25527987, 113.79352508, 114.47793746,\n",
       "        216.01555858, 221.40233474, 217.51725178, 219.89101772,\n",
       "        346.00540962, 350.91538811, 346.22162166, 351.35822139,\n",
       "        111.79588161, 111.72791634, 111.43988595, 112.15251975,\n",
       "        202.27888489, 202.08092828, 202.40353832, 202.76309614,\n",
       "        316.08276873, 314.53372769, 315.08581562, 316.4178896 ,\n",
       "        111.98209128, 111.25440583, 162.34689102, 123.29470859,\n",
       "        199.58491564, 208.24108105, 206.81913176, 201.04706526,\n",
       "        318.61726742, 304.16316924, 310.45060101, 313.79158854]),\n",
       " 'mean_score_time': array([24.87143817, 24.38471117, 24.44873095, 24.13946695, 32.28621159,\n",
       "        32.01074753, 32.65271969, 32.32181864, 42.40457387, 41.85908804,\n",
       "        42.57824063, 41.87049084, 24.44411626, 24.38904352, 24.74674668,\n",
       "        24.4685349 , 32.50605874, 32.23182397, 32.43457727, 32.21509986,\n",
       "        42.21142168, 41.83849673, 42.54568176, 42.12073712, 24.85778961,\n",
       "        24.76900024, 29.10343318, 27.93255939, 32.76645174, 36.22705693,\n",
       "        34.39418087, 33.77554345, 43.51056843, 42.93669381, 43.66104879,\n",
       "        46.19960856]),\n",
       " 'mean_test_score': array([0.10258663, 0.10844339, 0.12554211, 0.11690053, 0.09036204,\n",
       "        0.09170918, 0.10882002, 0.0969478 , 0.0802444 , 0.08799909,\n",
       "        0.09643028, 0.09121294, 0.13923448, 0.13947032, 0.17008709,\n",
       "        0.1433275 , 0.09681481, 0.09363069, 0.10866597, 0.10991502,\n",
       "        0.08886563, 0.09308657, 0.0969651 , 0.09988674, 0.13066824,\n",
       "        0.13611372, 0.16926229, 0.16125062, 0.09635856, 0.09796511,\n",
       "        0.10401131, 0.10744134, 0.10022719, 0.08046569, 0.08660245,\n",
       "        0.10135915]),\n",
       " 'param_clf__estimator__min_samples_split': masked_array(data=[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_clf__estimator__n_estimators': masked_array(data=[10, 10, 10, 10, 50, 50, 50, 50, 100, 100, 100, 100, 10,\n",
       "                    10, 10, 10, 50, 50, 50, 50, 100, 100, 100, 100, 10, 10,\n",
       "                    10, 10, 50, 50, 50, 50, 100, 100, 100, 100],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_tfidf__norm': masked_array(data=['l1', 'l1', 'l2', 'l2', 'l1', 'l1', 'l2', 'l2', 'l1',\n",
       "                    'l1', 'l2', 'l2', 'l1', 'l1', 'l2', 'l2', 'l1', 'l1',\n",
       "                    'l2', 'l2', 'l1', 'l1', 'l2', 'l2', 'l1', 'l1', 'l2',\n",
       "                    'l2', 'l1', 'l1', 'l2', 'l2', 'l1', 'l1', 'l2', 'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_tfidf__use_idf': masked_array(data=[True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__norm': 'l1',\n",
       "   'tfidf__use_idf': True},\n",
       "  {'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__norm': 'l1',\n",
       "   'tfidf__use_idf': False},\n",
       "  {'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__norm': 'l2',\n",
       "   'tfidf__use_idf': True},\n",
       "  {'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__norm': 'l2',\n",
       "   'tfidf__use_idf': False},\n",
       "  {'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 50,\n",
       "   'tfidf__norm': 'l1',\n",
       "   'tfidf__use_idf': True},\n",
       "  {'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 50,\n",
       "   'tfidf__norm': 'l1',\n",
       "   'tfidf__use_idf': False},\n",
       "  {'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 50,\n",
       "   'tfidf__norm': 'l2',\n",
       "   'tfidf__use_idf': True},\n",
       "  {'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 50,\n",
       "   'tfidf__norm': 'l2',\n",
       "   'tfidf__use_idf': False},\n",
       "  {'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 100,\n",
       "   'tfidf__norm': 'l1',\n",
       "   'tfidf__use_idf': True},\n",
       "  {'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 100,\n",
       "   'tfidf__norm': 'l1',\n",
       "   'tfidf__use_idf': False},\n",
       "  {'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 100,\n",
       "   'tfidf__norm': 'l2',\n",
       "   'tfidf__use_idf': True},\n",
       "  {'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 100,\n",
       "   'tfidf__norm': 'l2',\n",
       "   'tfidf__use_idf': False},\n",
       "  {'clf__estimator__min_samples_split': 3,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__norm': 'l1',\n",
       "   'tfidf__use_idf': True},\n",
       "  {'clf__estimator__min_samples_split': 3,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__norm': 'l1',\n",
       "   'tfidf__use_idf': False},\n",
       "  {'clf__estimator__min_samples_split': 3,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__norm': 'l2',\n",
       "   'tfidf__use_idf': True},\n",
       "  {'clf__estimator__min_samples_split': 3,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__norm': 'l2',\n",
       "   'tfidf__use_idf': False},\n",
       "  {'clf__estimator__min_samples_split': 3,\n",
       "   'clf__estimator__n_estimators': 50,\n",
       "   'tfidf__norm': 'l1',\n",
       "   'tfidf__use_idf': True},\n",
       "  {'clf__estimator__min_samples_split': 3,\n",
       "   'clf__estimator__n_estimators': 50,\n",
       "   'tfidf__norm': 'l1',\n",
       "   'tfidf__use_idf': False},\n",
       "  {'clf__estimator__min_samples_split': 3,\n",
       "   'clf__estimator__n_estimators': 50,\n",
       "   'tfidf__norm': 'l2',\n",
       "   'tfidf__use_idf': True},\n",
       "  {'clf__estimator__min_samples_split': 3,\n",
       "   'clf__estimator__n_estimators': 50,\n",
       "   'tfidf__norm': 'l2',\n",
       "   'tfidf__use_idf': False},\n",
       "  {'clf__estimator__min_samples_split': 3,\n",
       "   'clf__estimator__n_estimators': 100,\n",
       "   'tfidf__norm': 'l1',\n",
       "   'tfidf__use_idf': True},\n",
       "  {'clf__estimator__min_samples_split': 3,\n",
       "   'clf__estimator__n_estimators': 100,\n",
       "   'tfidf__norm': 'l1',\n",
       "   'tfidf__use_idf': False},\n",
       "  {'clf__estimator__min_samples_split': 3,\n",
       "   'clf__estimator__n_estimators': 100,\n",
       "   'tfidf__norm': 'l2',\n",
       "   'tfidf__use_idf': True},\n",
       "  {'clf__estimator__min_samples_split': 3,\n",
       "   'clf__estimator__n_estimators': 100,\n",
       "   'tfidf__norm': 'l2',\n",
       "   'tfidf__use_idf': False},\n",
       "  {'clf__estimator__min_samples_split': 4,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__norm': 'l1',\n",
       "   'tfidf__use_idf': True},\n",
       "  {'clf__estimator__min_samples_split': 4,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__norm': 'l1',\n",
       "   'tfidf__use_idf': False},\n",
       "  {'clf__estimator__min_samples_split': 4,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__norm': 'l2',\n",
       "   'tfidf__use_idf': True},\n",
       "  {'clf__estimator__min_samples_split': 4,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__norm': 'l2',\n",
       "   'tfidf__use_idf': False},\n",
       "  {'clf__estimator__min_samples_split': 4,\n",
       "   'clf__estimator__n_estimators': 50,\n",
       "   'tfidf__norm': 'l1',\n",
       "   'tfidf__use_idf': True},\n",
       "  {'clf__estimator__min_samples_split': 4,\n",
       "   'clf__estimator__n_estimators': 50,\n",
       "   'tfidf__norm': 'l1',\n",
       "   'tfidf__use_idf': False},\n",
       "  {'clf__estimator__min_samples_split': 4,\n",
       "   'clf__estimator__n_estimators': 50,\n",
       "   'tfidf__norm': 'l2',\n",
       "   'tfidf__use_idf': True},\n",
       "  {'clf__estimator__min_samples_split': 4,\n",
       "   'clf__estimator__n_estimators': 50,\n",
       "   'tfidf__norm': 'l2',\n",
       "   'tfidf__use_idf': False},\n",
       "  {'clf__estimator__min_samples_split': 4,\n",
       "   'clf__estimator__n_estimators': 100,\n",
       "   'tfidf__norm': 'l1',\n",
       "   'tfidf__use_idf': True},\n",
       "  {'clf__estimator__min_samples_split': 4,\n",
       "   'clf__estimator__n_estimators': 100,\n",
       "   'tfidf__norm': 'l1',\n",
       "   'tfidf__use_idf': False},\n",
       "  {'clf__estimator__min_samples_split': 4,\n",
       "   'clf__estimator__n_estimators': 100,\n",
       "   'tfidf__norm': 'l2',\n",
       "   'tfidf__use_idf': True},\n",
       "  {'clf__estimator__min_samples_split': 4,\n",
       "   'clf__estimator__n_estimators': 100,\n",
       "   'tfidf__norm': 'l2',\n",
       "   'tfidf__use_idf': False}],\n",
       " 'rank_test_score': array([17, 14,  9, 10, 31, 29, 12, 23, 36, 33, 25, 30,  6,  5,  1,  4, 24,\n",
       "        27, 13, 11, 32, 28, 22, 20,  8,  7,  2,  3, 26, 21, 16, 15, 19, 35,\n",
       "        34, 18], dtype=int32),\n",
       " 'split0_test_score': array([0.08253589, 0.07998084, 0.11378205, 0.09844517, 0.0585423 ,\n",
       "        0.06649475, 0.1036502 , 0.09269864, 0.07153303, 0.07095727,\n",
       "        0.0710283 , 0.0707449 , 0.11751361, 0.14004395, 0.15945654,\n",
       "        0.12144698, 0.10056568, 0.07719298, 0.0838637 , 0.11108828,\n",
       "        0.08537616, 0.0789532 , 0.09238319, 0.10831762, 0.13703911,\n",
       "        0.10724554, 0.18878976, 0.18025983, 0.07912547, 0.0770072 ,\n",
       "        0.09365473, 0.08977456, 0.0674692 , 0.06929807, 0.09143723,\n",
       "        0.09155667]),\n",
       " 'split1_test_score': array([0.10290347, 0.12488688, 0.13165694, 0.12139012, 0.09961419,\n",
       "        0.07677214, 0.10592334, 0.12964506, 0.09091207, 0.10837372,\n",
       "        0.11634333, 0.1135743 , 0.14730056, 0.13133333, 0.1471809 ,\n",
       "        0.16161674, 0.10589895, 0.07761923, 0.13964364, 0.11223776,\n",
       "        0.10699187, 0.10180624, 0.1123643 , 0.11441894, 0.14402609,\n",
       "        0.1723208 , 0.15692308, 0.15222225, 0.10062085, 0.10868408,\n",
       "        0.11906449, 0.122868  , 0.12232574, 0.09468116, 0.09468116,\n",
       "        0.10625243]),\n",
       " 'split2_test_score': array([0.10313663, 0.13443632, 0.13900914, 0.14409855, 0.09393267,\n",
       "        0.1275576 , 0.11178396, 0.1106059 , 0.08069966, 0.0981241 ,\n",
       "        0.08774874, 0.10405071, 0.17097564, 0.13418155, 0.18226143,\n",
       "        0.17657781, 0.11296208, 0.11292614, 0.10097737, 0.10184317,\n",
       "        0.09902669, 0.10651163, 0.10313663, 0.0946875 , 0.13556915,\n",
       "        0.12122449, 0.1969603 , 0.14656914, 0.11040936, 0.10699301,\n",
       "        0.11363636, 0.12470862, 0.13029402, 0.07682641, 0.10405071,\n",
       "        0.0981019 ]),\n",
       " 'split3_test_score': array([0.13397436, 0.09220907, 0.13333333, 0.11594388, 0.09479452,\n",
       "        0.10604575, 0.11584849, 0.08707145, 0.09092963, 0.0940422 ,\n",
       "        0.11745031, 0.08355066, 0.14817073, 0.15851852, 0.15204597,\n",
       "        0.11169623, 0.10238957, 0.1055447 , 0.11692747, 0.11610367,\n",
       "        0.08696063, 0.08685269, 0.0797351 , 0.10545285, 0.13396057,\n",
       "        0.14437768, 0.14026547, 0.17606007, 0.10548169, 0.10906439,\n",
       "        0.10940635, 0.11046805, 0.09545455, 0.0949595 , 0.07843137,\n",
       "        0.11959701]),\n",
       " 'split4_test_score': array([0.09038282, 0.11070384, 0.10992908, 0.10462493, 0.1049265 ,\n",
       "        0.08167566, 0.1068941 , 0.06471794, 0.06714761, 0.06849817,\n",
       "        0.08958074, 0.08414411, 0.11221183, 0.13327423, 0.2094906 ,\n",
       "        0.14529975, 0.06225775, 0.09487038, 0.10191769, 0.10830223,\n",
       "        0.06597279, 0.09130908, 0.09720629, 0.07655678, 0.1027463 ,\n",
       "        0.13540011, 0.16337286, 0.15114183, 0.08615543, 0.08807686,\n",
       "        0.08429459, 0.08938746, 0.08559245, 0.06656331, 0.06441176,\n",
       "        0.09128775]),\n",
       " 'std_fit_time': array([ 0.8266853 ,  1.03349799,  0.67945276,  0.3409793 ,  1.29920539,\n",
       "         2.61580977,  1.5169699 ,  1.30118129,  2.27012665,  1.46829458,\n",
       "         2.11480961,  2.18587601,  0.84823362,  0.98804908,  0.83911575,\n",
       "         0.99318277,  1.21573386,  0.83828569,  1.67653386,  0.99273769,\n",
       "         1.65834398,  1.79038214,  1.0896785 ,  2.51517535,  1.85855153,\n",
       "         1.51511501, 62.40464406, 11.35351162,  3.32875218, 16.31425502,\n",
       "         7.62252442,  1.17301287, 20.68344472,  3.14078842,  2.16714324,\n",
       "         8.39829657]),\n",
       " 'std_score_time': array([0.74135008, 0.68486362, 0.25264109, 0.42903695, 0.15259277,\n",
       "        0.28502562, 0.55177318, 0.82490057, 0.1902077 , 0.47871405,\n",
       "        0.23737736, 0.39120042, 0.45715754, 0.45538629, 0.64291512,\n",
       "        0.47404958, 0.71414296, 0.66632293, 0.43581076, 0.54447879,\n",
       "        0.38838206, 0.64448603, 0.42789712, 0.49142138, 0.60734743,\n",
       "        0.78809885, 6.91025743, 4.37881496, 0.75803226, 3.56674553,\n",
       "        1.65988225, 0.669115  , 0.85411967, 0.20537518, 0.4482278 ,\n",
       "        5.76629174]),\n",
       " 'std_test_score': array([0.0175303 , 0.02012362, 0.01150236, 0.01582463, 0.01638669,\n",
       "        0.02213685, 0.0044048 , 0.02195457, 0.00975289, 0.01565165,\n",
       "        0.01792159, 0.01544317, 0.02169995, 0.00995727, 0.02308261,\n",
       "        0.02417959, 0.01779097, 0.01443856, 0.01869585, 0.0047503 ,\n",
       "        0.01394055, 0.00998036, 0.01089172, 0.01330087, 0.01437716,\n",
       "        0.02206724, 0.02086269, 0.01399939, 0.01183137, 0.01308896,\n",
       "        0.01299503, 0.01538414, 0.02324823, 0.01219333, 0.01380055,\n",
       "        0.01062728])}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17008708900962954"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best mean test score\n",
    "np.max(result.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__estimator__min_samples_split': 3,\n",
       " 'clf__estimator__n_estimators': 10,\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__use_idf': True}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters for best mean test score\n",
    "result.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " ...\n",
      " [1 0 0 ... 1 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Predicted output based on test dataset\n",
    "y_pred = result.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/anaconda/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Precision    Recall  Accuracy        f1\n",
      "related                 0.837000   0.936919  0.812332  0.884146\n",
      "request                 0.784200   0.466743  0.889166  0.585191\n",
      "offer                   0.000000   0.000000  0.995390  0.000000\n",
      "aid_related             0.723996   0.640839  0.745678  0.679884\n",
      "medical_help            0.597403   0.103604  0.917595  0.176583\n",
      "medical_products        0.729730   0.097473  0.950058  0.171975\n",
      "search_and_rescue       0.619048   0.078313  0.969074  0.139037\n",
      "security                0.000000   0.000000  0.980983  0.000000\n",
      "military                0.312500   0.030303  0.967153  0.055249\n",
      "water                   0.833333   0.439883  0.957549  0.575816\n",
      "food                    0.802360   0.468966  0.927968  0.591948\n",
      "shelter                 0.720238   0.256900  0.923742  0.378717\n",
      "clothing                0.928571   0.191176  0.989243  0.317073\n",
      "money                   1.000000   0.026087  0.978486  0.050847\n",
      "missing_people          0.000000   0.000000  0.986554  0.000000\n",
      "refugees                0.500000   0.092896  0.964848  0.156682\n",
      "death                   0.886364   0.164557  0.961007  0.277580\n",
      "other_aid               0.511905   0.061871  0.866884  0.110398\n",
      "infrastructure_related  0.428571   0.016667  0.930465  0.032086\n",
      "transport               0.533333   0.097959  0.953515  0.165517\n",
      "buildings               0.689655   0.148699  0.952555  0.244648\n",
      "electricity             0.875000   0.060345  0.978871  0.112903\n",
      "tools                   0.000000   0.000000  0.994237  0.000000\n",
      "hospitals               1.000000   0.015152  0.987514  0.029851\n",
      "shops                   0.000000   0.000000  0.995198  0.000000\n",
      "aid_centers             0.000000   0.000000  0.988091  0.000000\n",
      "other_infrastructure    0.571429   0.016461  0.953515  0.032000\n",
      "weather_related         0.840000   0.652346  0.862851  0.734375\n",
      "floods                  0.908714   0.479212  0.950058  0.627507\n",
      "storm                   0.764331   0.465116  0.932770  0.578313\n",
      "fire                    0.500000   0.013889  0.986170  0.027027\n",
      "earthquake              0.875289   0.726054  0.962159  0.793717\n",
      "cold                    0.615385   0.086957  0.982904  0.152381\n",
      "other_weather           0.444444   0.030534  0.949289  0.057143\n"
     ]
    }
   ],
   "source": [
    "# Calculate performance metrics for each category\n",
    "metrics=[]\n",
    "for i in range(len(category_name)):\n",
    "    \n",
    "    precision=precision_score(list(y_test[:,i]),list(y_pred[:,i]))\n",
    "    recall=recall_score(y_test[:,i],y_pred[:,i])\n",
    "    accuracy=accuracy_score(y_test[:,i],y_pred[:,i])\n",
    "    f1=f1_score(y_test[:,i],y_pred[:,i])\n",
    "    metrics.append([precision,recall,accuracy,f1])\n",
    "\n",
    "# Metrics output\n",
    "metrics_output_test_2=pd.DataFrame(data=metrics,columns=['Precision','Recall','Accuracy','f1'],index = category_name)\n",
    "print (metrics_output_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.583318</td>\n",
       "      <td>0.201939</td>\n",
       "      <td>0.945408</td>\n",
       "      <td>0.257017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.321072</td>\n",
       "      <td>0.255059</td>\n",
       "      <td>0.054805</td>\n",
       "      <td>0.274885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.745678</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.016512</td>\n",
       "      <td>0.931041</td>\n",
       "      <td>0.032021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.654351</td>\n",
       "      <td>0.089926</td>\n",
       "      <td>0.959278</td>\n",
       "      <td>0.154531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.836084</td>\n",
       "      <td>0.394137</td>\n",
       "      <td>0.982424</td>\n",
       "      <td>0.526541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.936919</td>\n",
       "      <td>0.995390</td>\n",
       "      <td>0.884146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Precision     Recall   Accuracy         f1\n",
       "count  34.000000  34.000000  34.000000  34.000000\n",
       "mean   0.583318   0.201939   0.945408   0.257017 \n",
       "std    0.321072   0.255059   0.054805   0.274885 \n",
       "min    0.000000   0.000000   0.745678   0.000000 \n",
       "25%    0.458333   0.016512   0.931041   0.032021 \n",
       "50%    0.654351   0.089926   0.959278   0.154531 \n",
       "75%    0.836084   0.394137   0.982424   0.526541 \n",
       "max    1.000000   0.936919   0.995390   0.884146 "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_output_test_2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In stead of using Random Forest Tree, SVM might be a good approach since it leverages the kernel trick to transform your data and then based on these transformations, it finds an optimal boundary between the possible outputs, and Linear Support Vector Machine is widely regarded as one of the best text classification algorithms. (https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf': MultiOutputClassifier(estimator=LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                                           fit_intercept=True,\n",
       "                                           intercept_scaling=1,\n",
       "                                           loss='squared_hinge', max_iter=1000,\n",
       "                                           multi_class='ovr', penalty='l2',\n",
       "                                           random_state=None, tol=0.0001,\n",
       "                                           verbose=0),\n",
       "                       n_jobs=None),\n",
       " 'clf__estimator': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "           intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "           multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "           verbose=0),\n",
       " 'clf__estimator__C': 1.0,\n",
       " 'clf__estimator__class_weight': None,\n",
       " 'clf__estimator__dual': True,\n",
       " 'clf__estimator__fit_intercept': True,\n",
       " 'clf__estimator__intercept_scaling': 1,\n",
       " 'clf__estimator__loss': 'squared_hinge',\n",
       " 'clf__estimator__max_iter': 1000,\n",
       " 'clf__estimator__multi_class': 'ovr',\n",
       " 'clf__estimator__penalty': 'l2',\n",
       " 'clf__estimator__random_state': None,\n",
       " 'clf__estimator__tol': 0.0001,\n",
       " 'clf__estimator__verbose': 0,\n",
       " 'clf__n_jobs': None,\n",
       " 'memory': None,\n",
       " 'steps': [('vect',\n",
       "   CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                   dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                   lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                   ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                   strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                   tokenizer=<function tokenize at 0x7fd686ecbc80>,\n",
       "                   vocabulary=None)),\n",
       "  ('tfidf',\n",
       "   TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)),\n",
       "  ('clf',\n",
       "   MultiOutputClassifier(estimator=LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                                             fit_intercept=True,\n",
       "                                             intercept_scaling=1,\n",
       "                                             loss='squared_hinge', max_iter=1000,\n",
       "                                             multi_class='ovr', penalty='l2',\n",
       "                                             random_state=None, tol=0.0001,\n",
       "                                             verbose=0),\n",
       "                         n_jobs=None))],\n",
       " 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True),\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__use_idf': True,\n",
       " 'vect': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                 dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                 lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                 ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                 strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                 tokenizer=<function tokenize at 0x7fd686ecbc80>,\n",
       "                 vocabulary=None),\n",
       " 'vect__analyzer': 'word',\n",
       " 'vect__binary': False,\n",
       " 'vect__decode_error': 'strict',\n",
       " 'vect__dtype': numpy.int64,\n",
       " 'vect__encoding': 'utf-8',\n",
       " 'vect__input': 'content',\n",
       " 'vect__lowercase': True,\n",
       " 'vect__max_df': 1.0,\n",
       " 'vect__max_features': None,\n",
       " 'vect__min_df': 1,\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__preprocessor': None,\n",
       " 'vect__stop_words': None,\n",
       " 'vect__strip_accents': None,\n",
       " 'vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vect__tokenizer': <function __main__.tokenize>,\n",
       " 'vect__vocabulary': None,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline2 = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer = tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(LinearSVC()))\n",
    "])\n",
    "\n",
    "# Get the parameters name\n",
    "pipeline2.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "parameters_2 = {\n",
    "                'clf__estimator__class_weight':['balanced'],\n",
    "              'clf__estimator__max_iter': [1000,1500,2000],\n",
    "              'clf__estimator__C':[1,1.5,2]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define performance metric for use in grid search scoring object\n",
    "def performance_metric(y_true, y_pred):\n",
    "    \"\"\"Calculate median F1 score for all of the output classifiers\n",
    "    \n",
    "    Args:\n",
    "    y_true: array. Array containing actual labels.\n",
    "    y_pred: array. Array containing predicted labels.\n",
    "        \n",
    "    Returns:\n",
    "    score: float. Median F1 score for all of the output classifiers\n",
    "    \"\"\"\n",
    "    f1_list = []\n",
    "    for i in range(np.shape(y_pred)[1]):\n",
    "        f1 = f1_score(np.array(y_true)[:, i], y_pred[:, i])\n",
    "        f1_list.append(f1)\n",
    "        \n",
    "    score = np.median(f1_list)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1_scorer = make_scorer(performance_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] clf__estimator__C=1, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__C=1, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1000, score=0.447, total= 2.9min\n",
      "[CV] clf__estimator__C=1, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__C=1, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1000, score=0.424, total= 2.8min\n",
      "[CV] clf__estimator__C=1, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  5.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__C=1, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1000, score=0.453, total= 2.6min\n",
      "[CV] clf__estimator__C=1, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  8.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__C=1, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1000, score=0.421, total= 2.2min\n",
      "[CV] clf__estimator__C=1, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 10.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__C=1, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1000, score=0.411, total= 2.1min\n",
      "[CV] clf__estimator__C=1, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 12.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__C=1, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1500, score=0.447, total= 2.1min\n",
      "[CV] clf__estimator__C=1, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 14.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__C=1, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1500, score=0.424, total= 2.2min\n",
      "[CV] clf__estimator__C=1, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed: 16.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__C=1, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1500, score=0.453, total= 2.2min\n",
      "[CV] clf__estimator__C=1, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 19.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__C=1, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1500, score=0.421, total= 2.2min\n",
      "[CV] clf__estimator__C=1, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1500 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 21.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__C=1, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1500, score=0.411, total= 2.1min\n",
      "[CV] clf__estimator__C=1, clf__estimator__class_weight=balanced, clf__estimator__max_iter=2000 \n",
      "[CV]  clf__estimator__C=1, clf__estimator__class_weight=balanced, clf__estimator__max_iter=2000, score=0.447, total= 2.1min\n",
      "[CV] clf__estimator__C=1, clf__estimator__class_weight=balanced, clf__estimator__max_iter=2000 \n",
      "[CV]  clf__estimator__C=1, clf__estimator__class_weight=balanced, clf__estimator__max_iter=2000, score=0.424, total= 2.1min\n",
      "[CV] clf__estimator__C=1, clf__estimator__class_weight=balanced, clf__estimator__max_iter=2000 \n",
      "[CV]  clf__estimator__C=1, clf__estimator__class_weight=balanced, clf__estimator__max_iter=2000, score=0.453, total= 2.1min\n",
      "[CV] clf__estimator__C=1, clf__estimator__class_weight=balanced, clf__estimator__max_iter=2000 \n",
      "[CV]  clf__estimator__C=1, clf__estimator__class_weight=balanced, clf__estimator__max_iter=2000, score=0.421, total= 2.1min\n",
      "[CV] clf__estimator__C=1, clf__estimator__class_weight=balanced, clf__estimator__max_iter=2000 \n",
      "[CV]  clf__estimator__C=1, clf__estimator__class_weight=balanced, clf__estimator__max_iter=2000, score=0.411, total= 2.1min\n",
      "[CV] clf__estimator__C=1.5, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1000 \n",
      "[CV]  clf__estimator__C=1.5, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1000, score=0.439, total= 2.1min\n",
      "[CV] clf__estimator__C=1.5, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__C=1.5, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1000, score=0.422, total= 2.1min\n",
      "[CV] clf__estimator__C=1.5, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__C=1.5, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1000, score=0.434, total= 2.1min\n",
      "[CV] clf__estimator__C=1.5, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__C=1.5, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1000, score=0.423, total= 2.1min\n",
      "[CV] clf__estimator__C=1.5, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1000 \n",
      "[CV]  clf__estimator__C=1.5, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1000, score=0.406, total= 2.1min\n",
      "[CV] clf__estimator__C=1.5, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1500 \n",
      "[CV]  clf__estimator__C=1.5, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1500, score=0.439, total= 2.1min\n",
      "[CV] clf__estimator__C=1.5, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1500 \n",
      "[CV]  clf__estimator__C=1.5, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1500, score=0.422, total= 2.1min\n",
      "[CV] clf__estimator__C=1.5, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1500 \n",
      "[CV]  clf__estimator__C=1.5, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1500, score=0.434, total= 2.1min\n",
      "[CV] clf__estimator__C=1.5, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1500 \n",
      "[CV]  clf__estimator__C=1.5, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1500, score=0.423, total= 2.1min\n",
      "[CV] clf__estimator__C=1.5, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1500 \n",
      "[CV]  clf__estimator__C=1.5, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1500, score=0.406, total= 2.1min\n",
      "[CV] clf__estimator__C=1.5, clf__estimator__class_weight=balanced, clf__estimator__max_iter=2000 \n",
      "[CV]  clf__estimator__C=1.5, clf__estimator__class_weight=balanced, clf__estimator__max_iter=2000, score=0.439, total= 2.2min\n",
      "[CV] clf__estimator__C=1.5, clf__estimator__class_weight=balanced, clf__estimator__max_iter=2000 \n",
      "[CV]  clf__estimator__C=1.5, clf__estimator__class_weight=balanced, clf__estimator__max_iter=2000, score=0.422, total= 2.1min\n",
      "[CV] clf__estimator__C=1.5, clf__estimator__class_weight=balanced, clf__estimator__max_iter=2000 \n",
      "[CV]  clf__estimator__C=1.5, clf__estimator__class_weight=balanced, clf__estimator__max_iter=2000, score=0.434, total= 2.1min\n",
      "[CV] clf__estimator__C=1.5, clf__estimator__class_weight=balanced, clf__estimator__max_iter=2000 \n",
      "[CV]  clf__estimator__C=1.5, clf__estimator__class_weight=balanced, clf__estimator__max_iter=2000, score=0.423, total= 2.1min\n",
      "[CV] clf__estimator__C=1.5, clf__estimator__class_weight=balanced, clf__estimator__max_iter=2000 \n",
      "[CV]  clf__estimator__C=1.5, clf__estimator__class_weight=balanced, clf__estimator__max_iter=2000, score=0.406, total= 2.1min\n",
      "[CV] clf__estimator__C=2, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1000 \n",
      "[CV]  clf__estimator__C=2, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1000, score=0.431, total= 2.1min\n",
      "[CV] clf__estimator__C=2, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__C=2, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1000, score=0.418, total= 2.2min\n",
      "[CV] clf__estimator__C=2, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__C=2, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1000, score=0.424, total= 2.2min\n",
      "[CV] clf__estimator__C=2, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__C=2, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1000, score=0.412, total= 2.2min\n",
      "[CV] clf__estimator__C=2, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/anaconda/lib/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__C=2, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1000, score=0.400, total= 2.1min\n",
      "[CV] clf__estimator__C=2, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1500 \n",
      "[CV]  clf__estimator__C=2, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1500, score=0.431, total= 2.2min\n",
      "[CV] clf__estimator__C=2, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1500 \n",
      "[CV]  clf__estimator__C=2, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1500, score=0.418, total= 2.1min\n",
      "[CV] clf__estimator__C=2, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1500 \n",
      "[CV]  clf__estimator__C=2, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1500, score=0.424, total= 2.1min\n",
      "[CV] clf__estimator__C=2, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1500 \n",
      "[CV]  clf__estimator__C=2, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1500, score=0.412, total= 2.2min\n",
      "[CV] clf__estimator__C=2, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1500 \n",
      "[CV]  clf__estimator__C=2, clf__estimator__class_weight=balanced, clf__estimator__max_iter=1500, score=0.400, total= 2.1min\n",
      "[CV] clf__estimator__C=2, clf__estimator__class_weight=balanced, clf__estimator__max_iter=2000 \n",
      "[CV]  clf__estimator__C=2, clf__estimator__class_weight=balanced, clf__estimator__max_iter=2000, score=0.431, total= 2.1min\n",
      "[CV] clf__estimator__C=2, clf__estimator__class_weight=balanced, clf__estimator__max_iter=2000 \n",
      "[CV]  clf__estimator__C=2, clf__estimator__class_weight=balanced, clf__estimator__max_iter=2000, score=0.418, total= 2.1min\n",
      "[CV] clf__estimator__C=2, clf__estimator__class_weight=balanced, clf__estimator__max_iter=2000 \n",
      "[CV]  clf__estimator__C=2, clf__estimator__class_weight=balanced, clf__estimator__max_iter=2000, score=0.424, total= 2.1min\n",
      "[CV] clf__estimator__C=2, clf__estimator__class_weight=balanced, clf__estimator__max_iter=2000 \n",
      "[CV]  clf__estimator__C=2, clf__estimator__class_weight=balanced, clf__estimator__max_iter=2000, score=0.412, total= 2.1min\n",
      "[CV] clf__estimator__C=2, clf__estimator__class_weight=balanced, clf__estimator__max_iter=2000 \n",
      "[CV]  clf__estimator__C=2, clf__estimator__class_weight=balanced, clf__estimator__max_iter=2000, score=0.400, total= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed: 97.8min finished\n"
     ]
    }
   ],
   "source": [
    "cv_2 = GridSearchCV(pipeline2, param_grid=parameters_2,scoring=f1_scorer,verbose=10)\n",
    "# Find best parameters\n",
    "tuned_model2 = cv_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([124.7038785 , 104.92378936, 103.28324022, 103.44506936,\n",
       "        102.54043016, 104.06883798, 105.74800549, 105.25830789,\n",
       "        104.69944363]),\n",
       " 'mean_score_time': array([26.36965842, 24.15577803, 23.76356578, 23.30771747, 23.2612699 ,\n",
       "        23.37091317, 23.47102389, 23.54595919, 23.33903775]),\n",
       " 'mean_test_score': array([0.43121831, 0.43121831, 0.43121831, 0.42475608, 0.42475608,\n",
       "        0.42475608, 0.41711915, 0.41711915, 0.41711915]),\n",
       " 'param_clf__estimator__C': masked_array(data=[1, 1, 1, 1.5, 1.5, 1.5, 2, 2, 2],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_clf__estimator__class_weight': masked_array(data=['balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced', 'balanced', 'balanced', 'balanced',\n",
       "                    'balanced'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_clf__estimator__max_iter': masked_array(data=[1000, 1500, 2000, 1000, 1500, 2000, 1000, 1500, 2000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'clf__estimator__C': 1,\n",
       "   'clf__estimator__class_weight': 'balanced',\n",
       "   'clf__estimator__max_iter': 1000},\n",
       "  {'clf__estimator__C': 1,\n",
       "   'clf__estimator__class_weight': 'balanced',\n",
       "   'clf__estimator__max_iter': 1500},\n",
       "  {'clf__estimator__C': 1,\n",
       "   'clf__estimator__class_weight': 'balanced',\n",
       "   'clf__estimator__max_iter': 2000},\n",
       "  {'clf__estimator__C': 1.5,\n",
       "   'clf__estimator__class_weight': 'balanced',\n",
       "   'clf__estimator__max_iter': 1000},\n",
       "  {'clf__estimator__C': 1.5,\n",
       "   'clf__estimator__class_weight': 'balanced',\n",
       "   'clf__estimator__max_iter': 1500},\n",
       "  {'clf__estimator__C': 1.5,\n",
       "   'clf__estimator__class_weight': 'balanced',\n",
       "   'clf__estimator__max_iter': 2000},\n",
       "  {'clf__estimator__C': 2,\n",
       "   'clf__estimator__class_weight': 'balanced',\n",
       "   'clf__estimator__max_iter': 1000},\n",
       "  {'clf__estimator__C': 2,\n",
       "   'clf__estimator__class_weight': 'balanced',\n",
       "   'clf__estimator__max_iter': 1500},\n",
       "  {'clf__estimator__C': 2,\n",
       "   'clf__estimator__class_weight': 'balanced',\n",
       "   'clf__estimator__max_iter': 2000}],\n",
       " 'rank_test_score': array([1, 1, 1, 4, 4, 4, 7, 7, 7], dtype=int32),\n",
       " 'split0_test_score': array([0.44749093, 0.44749093, 0.44749093, 0.4390283 , 0.4390283 ,\n",
       "        0.4390283 , 0.43102435, 0.43102435, 0.43102435]),\n",
       " 'split1_test_score': array([0.42390876, 0.42390876, 0.42390876, 0.42187271, 0.42187271,\n",
       "        0.42187271, 0.4180896 , 0.4180896 , 0.4180896 ]),\n",
       " 'split2_test_score': array([0.45286901, 0.45286901, 0.45286901, 0.43421224, 0.43421224,\n",
       "        0.43421224, 0.42430345, 0.42430345, 0.42430345]),\n",
       " 'split3_test_score': array([0.42102768, 0.42102768, 0.42102768, 0.42271242, 0.42271242,\n",
       "        0.42271242, 0.41174066, 0.41174066, 0.41174066]),\n",
       " 'split4_test_score': array([0.41079516, 0.41079516, 0.41079516, 0.40595474, 0.40595474,\n",
       "        0.40595474, 0.4004377 , 0.4004377 , 0.4004377 ]),\n",
       " 'std_fit_time': array([16.17157238,  0.5397579 ,  0.42653219,  1.08618563,  0.29199373,\n",
       "         1.06322221,  1.56822826,  0.52394882,  0.45288307]),\n",
       " 'std_score_time': array([3.00873545, 0.44024925, 0.73002084, 0.61738582, 0.36224363,\n",
       "        0.37581945, 0.55809244, 1.02779714, 0.36033032]),\n",
       " 'std_test_score': array([0.01617365, 0.01617365, 0.01617365, 0.01148126, 0.01148126,\n",
       "        0.01148126, 0.01051769, 0.01051769, 0.01051769])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get results of grid search\n",
    "tuned_model2.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the predicted result on test dataset\n",
    "y_test_predicted_2=tuned_model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Precision    Recall  Accuracy        f1\n",
      "related                 0.895806   0.842674  0.804841  0.868428\n",
      "request                 0.576887   0.709862  0.864195  0.636504\n",
      "offer                   0.058824   0.083333  0.989627  0.068966\n",
      "aid_related             0.716990   0.725160  0.763542  0.721051\n",
      "medical_help            0.368254   0.522523  0.882828  0.432030\n",
      "medical_products        0.351621   0.509025  0.923934  0.415929\n",
      "search_and_rescue       0.244019   0.307229  0.947561  0.272000\n",
      "security                0.064815   0.071429  0.963119  0.067961\n",
      "military                0.453552   0.503030  0.965040  0.477011\n",
      "water                   0.644769   0.777126  0.957357  0.704787\n",
      "food                    0.696562   0.803448  0.939109  0.746197\n",
      "shelter                 0.563725   0.732484  0.924510  0.637119\n",
      "clothing                0.506667   0.558824  0.987130  0.531469\n",
      "money                   0.337278   0.495652  0.967345  0.401408\n",
      "missing_people          0.237288   0.200000  0.980599  0.217054\n",
      "refugees                0.334661   0.459016  0.948905  0.387097\n",
      "death                   0.519031   0.632911  0.956589  0.570342\n",
      "other_aid               0.293088   0.457554  0.780254  0.357303\n",
      "infrastructure_related  0.201821   0.369444  0.855359  0.261040\n",
      "transport               0.220253   0.355102  0.910488  0.271875\n",
      "buildings               0.405063   0.594796  0.933922  0.481928\n",
      "electricity             0.355932   0.362069  0.971187  0.358974\n",
      "tools                   0.000000   0.000000  0.990396  0.000000\n",
      "hospitals               0.220588   0.227273  0.980023  0.223881\n",
      "shops                   0.181818   0.080000  0.993853  0.111111\n",
      "aid_centers             0.178571   0.241935  0.977718  0.205479\n",
      "other_infrastructure    0.158879   0.279835  0.897234  0.202683\n",
      "weather_related         0.755428   0.781890  0.863043  0.768431\n",
      "floods                  0.565378   0.671772  0.925855  0.614000\n",
      "storm                   0.651515   0.750000  0.935459  0.697297\n",
      "fire                    0.464286   0.361111  0.985401  0.406250\n",
      "earthquake              0.779197   0.818008  0.958509  0.798131\n",
      "cold                    0.386555   0.500000  0.977142  0.436019\n",
      "other_weather           0.251020   0.469466  0.902804  0.327128\n"
     ]
    }
   ],
   "source": [
    "# Calculate performance metrics for each category\n",
    "metrics=[]\n",
    "for i in range(len(category_name)):\n",
    "    \n",
    "    precision=precision_score(list(y_test[:,i]),list(y_test_predicted_2[:,i]))\n",
    "    recall=recall_score(y_test[:,i],y_test_predicted_2[:,i])\n",
    "    accuracy=accuracy_score(y_test[:,i],y_test_predicted_2[:,i])\n",
    "    f1=f1_score(y_test[:,i],y_test_predicted_2[:,i])\n",
    "    metrics.append([precision,recall,accuracy,f1])\n",
    "\n",
    "# Metrics output\n",
    "metrics_output_test_3=pd.DataFrame(data=metrics,columns=['Precision','Recall','Accuracy','f1'],index = category_name)\n",
    "print (metrics_output_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.401181</td>\n",
       "      <td>0.478058</td>\n",
       "      <td>0.929555</td>\n",
       "      <td>0.431673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.226362</td>\n",
       "      <td>0.240146</td>\n",
       "      <td>0.060386</td>\n",
       "      <td>0.231525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.763542</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.224763</td>\n",
       "      <td>0.319197</td>\n",
       "      <td>0.904725</td>\n",
       "      <td>0.263749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.362093</td>\n",
       "      <td>0.497826</td>\n",
       "      <td>0.948233</td>\n",
       "      <td>0.411090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.564965</td>\n",
       "      <td>0.700340</td>\n",
       "      <td>0.975653</td>\n",
       "      <td>0.630878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.895806</td>\n",
       "      <td>0.842674</td>\n",
       "      <td>0.993853</td>\n",
       "      <td>0.868428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Precision     Recall   Accuracy         f1\n",
       "count  34.000000  34.000000  34.000000  34.000000\n",
       "mean   0.401181   0.478058   0.929555   0.431673 \n",
       "std    0.226362   0.240146   0.060386   0.231525 \n",
       "min    0.000000   0.000000   0.763542   0.000000 \n",
       "25%    0.224763   0.319197   0.904725   0.263749 \n",
       "50%    0.362093   0.497826   0.948233   0.411090 \n",
       "75%    0.564965   0.700340   0.975653   0.630878 \n",
       "max    0.895806   0.842674   0.993853   0.868428 "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_output_test_3.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we could see, the model is improved based on the median f1 value. Let's try Adaboost, since it is best used to boost the performance of decision trees on binary classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline3 = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer = tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(AdaBoostClassifier()))\n",
    "])\n",
    "\n",
    "# Get the parameters name\n",
    "#pipeline3.get_params()\n",
    "parameters3 = {\n",
    "        'vect__min_df':[1,10,50],\n",
    "        'clf__estimator__learning_rate': [0.001, 0.01, 0.1]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
      "[CV] clf__estimator__learning_rate=0.001, vect__min_df=1 .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__learning_rate=0.001, vect__min_df=1, score=0.120, total= 3.2min\n",
      "[CV] clf__estimator__learning_rate=0.001, vect__min_df=1 .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__learning_rate=0.001, vect__min_df=1, score=0.193, total= 3.9min\n",
      "[CV] clf__estimator__learning_rate=0.001, vect__min_df=1 .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  7.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__learning_rate=0.001, vect__min_df=1, score=0.118, total= 4.0min\n",
      "[CV] clf__estimator__learning_rate=0.001, vect__min_df=1 .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 11.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__learning_rate=0.001, vect__min_df=1, score=0.224, total= 3.8min\n",
      "[CV] clf__estimator__learning_rate=0.001, vect__min_df=1 .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 15.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__learning_rate=0.001, vect__min_df=1, score=0.219, total= 3.8min\n",
      "[CV] clf__estimator__learning_rate=0.001, vect__min_df=10 ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 18.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__learning_rate=0.001, vect__min_df=10, score=0.174, total= 3.5min\n",
      "[CV] clf__estimator__learning_rate=0.001, vect__min_df=10 ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 22.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__learning_rate=0.001, vect__min_df=10, score=0.205, total= 3.6min\n",
      "[CV] clf__estimator__learning_rate=0.001, vect__min_df=10 ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed: 25.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__learning_rate=0.001, vect__min_df=10, score=0.118, total= 3.6min\n",
      "[CV] clf__estimator__learning_rate=0.001, vect__min_df=10 ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 29.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__learning_rate=0.001, vect__min_df=10, score=0.223, total= 3.6min\n",
      "[CV] clf__estimator__learning_rate=0.001, vect__min_df=10 ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 33.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__learning_rate=0.001, vect__min_df=10, score=0.215, total= 3.7min\n",
      "[CV] clf__estimator__learning_rate=0.001, vect__min_df=50 ............\n",
      "[CV]  clf__estimator__learning_rate=0.001, vect__min_df=50, score=0.174, total= 3.5min\n",
      "[CV] clf__estimator__learning_rate=0.001, vect__min_df=50 ............\n",
      "[CV]  clf__estimator__learning_rate=0.001, vect__min_df=50, score=0.199, total= 3.5min\n",
      "[CV] clf__estimator__learning_rate=0.001, vect__min_df=50 ............\n",
      "[CV]  clf__estimator__learning_rate=0.001, vect__min_df=50, score=0.118, total= 3.4min\n",
      "[CV] clf__estimator__learning_rate=0.001, vect__min_df=50 ............\n",
      "[CV]  clf__estimator__learning_rate=0.001, vect__min_df=50, score=0.222, total= 3.4min\n",
      "[CV] clf__estimator__learning_rate=0.001, vect__min_df=50 ............\n",
      "[CV]  clf__estimator__learning_rate=0.001, vect__min_df=50, score=0.217, total= 3.5min\n",
      "[CV] clf__estimator__learning_rate=0.01, vect__min_df=1 ..............\n",
      "[CV]  clf__estimator__learning_rate=0.01, vect__min_df=1, score=0.025, total= 3.9min\n",
      "[CV] clf__estimator__learning_rate=0.01, vect__min_df=1 ..............\n",
      "[CV]  clf__estimator__learning_rate=0.01, vect__min_df=1, score=0.044, total= 3.9min\n",
      "[CV] clf__estimator__learning_rate=0.01, vect__min_df=1 ..............\n",
      "[CV]  clf__estimator__learning_rate=0.01, vect__min_df=1, score=0.018, total= 3.9min\n",
      "[CV] clf__estimator__learning_rate=0.01, vect__min_df=1 ..............\n",
      "[CV]  clf__estimator__learning_rate=0.01, vect__min_df=1, score=0.025, total= 4.0min\n",
      "[CV] clf__estimator__learning_rate=0.01, vect__min_df=1 ..............\n",
      "[CV]  clf__estimator__learning_rate=0.01, vect__min_df=1, score=0.038, total= 3.9min\n",
      "[CV] clf__estimator__learning_rate=0.01, vect__min_df=10 .............\n",
      "[CV]  clf__estimator__learning_rate=0.01, vect__min_df=10, score=0.025, total= 3.7min\n",
      "[CV] clf__estimator__learning_rate=0.01, vect__min_df=10 .............\n",
      "[CV]  clf__estimator__learning_rate=0.01, vect__min_df=10, score=0.044, total= 3.2min\n",
      "[CV] clf__estimator__learning_rate=0.01, vect__min_df=10 .............\n",
      "[CV]  clf__estimator__learning_rate=0.01, vect__min_df=10, score=0.018, total= 3.0min\n",
      "[CV] clf__estimator__learning_rate=0.01, vect__min_df=10 .............\n",
      "[CV]  clf__estimator__learning_rate=0.01, vect__min_df=10, score=0.025, total= 3.0min\n",
      "[CV] clf__estimator__learning_rate=0.01, vect__min_df=10 .............\n",
      "[CV]  clf__estimator__learning_rate=0.01, vect__min_df=10, score=0.038, total= 3.0min\n",
      "[CV] clf__estimator__learning_rate=0.01, vect__min_df=50 .............\n",
      "[CV]  clf__estimator__learning_rate=0.01, vect__min_df=50, score=0.025, total= 2.8min\n",
      "[CV] clf__estimator__learning_rate=0.01, vect__min_df=50 .............\n",
      "[CV]  clf__estimator__learning_rate=0.01, vect__min_df=50, score=0.044, total= 2.8min\n",
      "[CV] clf__estimator__learning_rate=0.01, vect__min_df=50 .............\n",
      "[CV]  clf__estimator__learning_rate=0.01, vect__min_df=50, score=0.018, total= 2.8min\n",
      "[CV] clf__estimator__learning_rate=0.01, vect__min_df=50 .............\n",
      "[CV]  clf__estimator__learning_rate=0.01, vect__min_df=50, score=0.025, total= 2.6min\n",
      "[CV] clf__estimator__learning_rate=0.01, vect__min_df=50 .............\n",
      "[CV]  clf__estimator__learning_rate=0.01, vect__min_df=50, score=0.038, total= 2.6min\n",
      "[CV] clf__estimator__learning_rate=0.1, vect__min_df=1 ...............\n",
      "[CV]  clf__estimator__learning_rate=0.1, vect__min_df=1, score=0.082, total= 2.9min\n",
      "[CV] clf__estimator__learning_rate=0.1, vect__min_df=1 ...............\n",
      "[CV]  clf__estimator__learning_rate=0.1, vect__min_df=1, score=0.120, total= 2.9min\n",
      "[CV] clf__estimator__learning_rate=0.1, vect__min_df=1 ...............\n",
      "[CV]  clf__estimator__learning_rate=0.1, vect__min_df=1, score=0.105, total= 2.9min\n",
      "[CV] clf__estimator__learning_rate=0.1, vect__min_df=1 ...............\n",
      "[CV]  clf__estimator__learning_rate=0.1, vect__min_df=1, score=0.107, total= 2.9min\n",
      "[CV] clf__estimator__learning_rate=0.1, vect__min_df=1 ...............\n",
      "[CV]  clf__estimator__learning_rate=0.1, vect__min_df=1, score=0.089, total= 3.0min\n",
      "[CV] clf__estimator__learning_rate=0.1, vect__min_df=10 ..............\n",
      "[CV]  clf__estimator__learning_rate=0.1, vect__min_df=10, score=0.087, total= 2.7min\n",
      "[CV] clf__estimator__learning_rate=0.1, vect__min_df=10 ..............\n",
      "[CV]  clf__estimator__learning_rate=0.1, vect__min_df=10, score=0.120, total= 2.8min\n",
      "[CV] clf__estimator__learning_rate=0.1, vect__min_df=10 ..............\n",
      "[CV]  clf__estimator__learning_rate=0.1, vect__min_df=10, score=0.093, total= 2.7min\n",
      "[CV] clf__estimator__learning_rate=0.1, vect__min_df=10 ..............\n",
      "[CV]  clf__estimator__learning_rate=0.1, vect__min_df=10, score=0.107, total= 2.8min\n",
      "[CV] clf__estimator__learning_rate=0.1, vect__min_df=10 ..............\n",
      "[CV]  clf__estimator__learning_rate=0.1, vect__min_df=10, score=0.089, total= 2.7min\n",
      "[CV] clf__estimator__learning_rate=0.1, vect__min_df=50 ..............\n",
      "[CV]  clf__estimator__learning_rate=0.1, vect__min_df=50, score=0.096, total= 2.9min\n",
      "[CV] clf__estimator__learning_rate=0.1, vect__min_df=50 ..............\n",
      "[CV]  clf__estimator__learning_rate=0.1, vect__min_df=50, score=0.121, total= 2.6min\n",
      "[CV] clf__estimator__learning_rate=0.1, vect__min_df=50 ..............\n",
      "[CV]  clf__estimator__learning_rate=0.1, vect__min_df=50, score=0.089, total= 2.6min\n",
      "[CV] clf__estimator__learning_rate=0.1, vect__min_df=50 ..............\n",
      "[CV]  clf__estimator__learning_rate=0.1, vect__min_df=50, score=0.100, total= 2.7min\n",
      "[CV] clf__estimator__learning_rate=0.1, vect__min_df=50 ..............\n",
      "[CV]  clf__estimator__learning_rate=0.1, vect__min_df=50, score=0.089, total= 2.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed: 144.9min finished\n"
     ]
    }
   ],
   "source": [
    "f1_scorer = make_scorer(performance_metric)\n",
    "cv_3 = GridSearchCV(pipeline3, param_grid=parameters3,scoring=f1_scorer,verbose=10)\n",
    "# Find best parameters\n",
    "tuned_model3 = cv_3.fit(X_train, y_train)\n",
    "tuned_model3.cv_results_\n",
    "# Get the predicted result on test dataset\n",
    "y_test_predicted_3=tuned_model3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/anaconda/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Precision    Recall  Accuracy        f1\n",
      "related                 0.764310   1.000000  0.764310  0.866413\n",
      "request                 0.790909   0.099771  0.844794  0.177189\n",
      "offer                   0.000000   0.000000  0.995390  0.000000\n",
      "aid_related             0.777154   0.189152  0.635421  0.304252\n",
      "medical_help            0.701149   0.137387  0.921437  0.229755\n",
      "medical_products        1.000000   0.003610  0.946984  0.007194\n",
      "search_and_rescue       0.566038   0.180723  0.969458  0.273973\n",
      "security                0.000000   0.000000  0.981176  0.000000\n",
      "military                0.522727   0.139394  0.968690  0.220096\n",
      "water                   0.564516   0.821114  0.946792  0.669056\n",
      "food                    0.734082   0.675862  0.936612  0.703770\n",
      "shelter                 0.794595   0.312102  0.930465  0.448171\n",
      "clothing                0.722222   0.573529  0.991548  0.639344\n",
      "money                   0.000000   0.000000  0.977910  0.000000\n",
      "missing_people          0.000000   0.000000  0.986554  0.000000\n",
      "refugees                0.625000   0.027322  0.965232  0.052356\n",
      "death                   0.632184   0.232068  0.958894  0.339506\n",
      "other_aid               0.000000   0.000000  0.866500  0.000000\n",
      "infrastructure_related  0.000000   0.000000  0.930849  0.000000\n",
      "transport               0.510000   0.208163  0.953323  0.295652\n",
      "buildings               0.000000   0.000000  0.948329  0.000000\n",
      "electricity             0.000000   0.000000  0.977718  0.000000\n",
      "tools                   0.000000   0.000000  0.994430  0.000000\n",
      "hospitals               0.000000   0.000000  0.987322  0.000000\n",
      "shops                   0.000000   0.000000  0.995198  0.000000\n",
      "aid_centers             0.000000   0.000000  0.988091  0.000000\n",
      "other_infrastructure    0.000000   0.000000  0.953323  0.000000\n",
      "weather_related         0.917333   0.227363  0.769497  0.364407\n",
      "floods                  0.909434   0.527352  0.953899  0.667590\n",
      "storm                   0.739796   0.281008  0.918940  0.407303\n",
      "fire                    0.000000   0.000000  0.986170  0.000000\n",
      "earthquake              0.912000   0.655172  0.959086  0.762542\n",
      "cold                    0.500000   0.021739  0.982328  0.041667\n",
      "other_weather           0.557377   0.129771  0.951018  0.210526\n"
     ]
    }
   ],
   "source": [
    "# Calculate performance metrics for each category\n",
    "metrics=[]\n",
    "for i in range(len(category_name)):\n",
    "    \n",
    "    precision=precision_score(list(y_test[:,i]),list(y_test_predicted_3[:,i]))\n",
    "    recall=recall_score(y_test[:,i],y_test_predicted_3[:,i])\n",
    "    accuracy=accuracy_score(y_test[:,i],y_test_predicted_3[:,i])\n",
    "    f1=f1_score(y_test[:,i],y_test_predicted_3[:,i])\n",
    "    metrics.append([precision,recall,accuracy,f1])\n",
    "\n",
    "# Metrics output\n",
    "metrics_output_test_4=pd.DataFrame(data=metrics,columns=['Precision','Recall','Accuracy','f1'],index = category_name)\n",
    "print (metrics_output_test_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.418848</td>\n",
       "      <td>0.189488</td>\n",
       "      <td>0.936403</td>\n",
       "      <td>0.225905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.373493</td>\n",
       "      <td>0.270047</td>\n",
       "      <td>0.077562</td>\n",
       "      <td>0.272236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.635421</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.932290</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540052</td>\n",
       "      <td>0.063547</td>\n",
       "      <td>0.956396</td>\n",
       "      <td>0.114773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.738368</td>\n",
       "      <td>0.230891</td>\n",
       "      <td>0.982040</td>\n",
       "      <td>0.358182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995390</td>\n",
       "      <td>0.866413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Precision     Recall   Accuracy         f1\n",
       "count  34.000000  34.000000  34.000000  34.000000\n",
       "mean   0.418848   0.189488   0.936403   0.225905 \n",
       "std    0.373493   0.270047   0.077562   0.272236 \n",
       "min    0.000000   0.000000   0.635421   0.000000 \n",
       "25%    0.000000   0.000000   0.932290   0.000000 \n",
       "50%    0.540052   0.063547   0.956396   0.114773 \n",
       "75%    0.738368   0.230891   0.982040   0.358182 \n",
       "max    1.000000   1.000000   0.995390   0.866413 "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_output_test_4.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the performance from different algorithms tryout, LinearSVC outperformed which will used as the final classification method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tuned_model2, open('models/classifier.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
